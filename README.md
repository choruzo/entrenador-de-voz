# Entrenador de Voz - Piper TTS

üéôÔ∏è Scripts y gu√≠as para entrenar modelos de voz personalizados usando Piper TTS en espa√±ol.

## üìã Descripci√≥n

Este repositorio contiene herramientas, scripts y documentaci√≥n completa para entrenar tu propio modelo de s√≠ntesis de voz (TTS) en espa√±ol usando [Piper](https://github.com/rhasspy/piper). Los scripts est√°n disponibles tanto en bash (Linux) como en Python (compatible con Windows, Linux y macOS).

## ‚ú® Caracter√≠sticas

- üìñ **Gu√≠a completa en espa√±ol** con instrucciones paso a paso
- üöÄ **Scripts automatizados** para configuraci√≥n, preprocesamiento, entrenamiento y exportaci√≥n
- ü™ü **Compatible con Windows 11, Linux y macOS** - Scripts en Python multiplataforma
- üîß **Optimizado para AMD GPU** con ROCm y **NVIDIA GPU** con CUDA
- üéØ **Transfer learning** desde modelos base en espa√±ol (es_ES-sharvard-medium)
- üõ†Ô∏è **Herramientas de validaci√≥n** de datasets
- üéµ **Utilidades de limpieza de audio**

## üéØ Objetivo

Entrenar modelos de voz que suenen **m√°s fluidos y menos rob√≥ticos** que los modelos base, personalizados con tu propia voz o dataset en espa√±ol.

## üöÄ Inicio R√°pido

### 1. Clonar el repositorio

```bash
git clone https://github.com/choruzo/entrenador-de-voz.git
cd entrenador-de-voz
```

### 2. Ejecutar configuraci√≥n inicial

#### En Windows:
```powershell
python scripts/setup.py
```

#### En Linux/macOS:
```bash
# Usando Python (recomendado para compatibilidad)
python3 scripts/setup.py

# O usando bash (solo Linux)
chmod +x scripts/*.sh
./scripts/setup.sh
```

Este script instalar√°:
- PyTorch con soporte GPU (ROCm para AMD, CUDA para NVIDIA) o CPU
- Piper training
- Dependencias necesarias

### 3. Preparar tu dataset

Crea un dataset en formato LJSpeech:

```
mi_dataset/
‚îú‚îÄ‚îÄ wavs/
‚îÇ   ‚îú‚îÄ‚îÄ audio001.wav
‚îÇ   ‚îú‚îÄ‚îÄ audio002.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metadata.csv
```

**Formato de metadata.csv:**
```
audio001|Este es el texto del primer audio.
audio002|Texto del segundo audio con puntuaci√≥n correcta.
```

### 4. Validar el dataset

```bash
python scripts/validar_dataset.py mi_dataset
```

### 5. Preprocesar los datos

#### En Windows:
```powershell
python scripts\preprocess.py mi_dataset dataset_procesado --language es-es
```

#### En Linux/macOS:
```bash
# Usando Python (recomendado)
python scripts/preprocess.py mi_dataset dataset_procesado --language es-es

# O usando bash (solo Linux)
./scripts/preprocess.sh mi_dataset dataset_procesado es-es
```

### 6. Entrenar el modelo

#### En Windows:
```powershell
python scripts\train.py dataset_procesado modelos_base\es_ES-sharvard-medium.ckpt
```

#### En Linux/macOS:
```bash
# Usando Python (recomendado)
python scripts/train.py dataset_procesado modelos_base/es_ES-sharvard-medium.ckpt

# O usando bash (solo Linux)
./scripts/train.sh dataset_procesado modelos_base/es_ES-sharvard-medium.ckpt
```

### 7. Exportar el modelo

#### En Windows:
```powershell
python scripts\export.py checkpoints\modelo-final.ckpt mi_voz_es.onnx
```

#### En Linux/macOS:
```bash
# Usando Python (recomendado)
python scripts/export.py checkpoints/modelo-final.ckpt mi_voz_es.onnx

# O usando bash (solo Linux)
./scripts/export.sh checkpoints/modelo-final.ckpt mi_voz_es.onnx
```

### 8. Probar tu voz

#### En Windows:
```powershell
echo "Hola, esta es mi voz personalizada" | piper --model mi_voz_es.onnx --output_file prueba.wav
# Abre prueba.wav con tu reproductor predeterminado
```

#### En Linux/macOS:
```bash
echo "Hola, esta es mi voz personalizada" | piper --model mi_voz_es.onnx --output_file prueba.wav
aplay prueba.wav  # Linux
afplay prueba.wav # macOS
```

## üìö Documentaci√≥n

### Gu√≠as Principales

- **[GUIA_ENTRENAMIENTO.md](GUIA_ENTRENAMIENTO.md)** - Gu√≠a completa y detallada para Linux
  - Requisitos del sistema
  - Instalaci√≥n paso a paso
  - Preparaci√≥n de datasets
  - Proceso de entrenamiento
  - Optimizaciones para tu hardware
  - Consejos para mejorar la fluidez
  - Soluci√≥n de problemas

- **[GUIA_WINDOWS.md](GUIA_WINDOWS.md)** - Gu√≠a espec√≠fica para Windows 11 ‚≠ê NUEVO
  - Instalaci√≥n en Windows
  - Configuraci√≥n de dependencias
  - Uso de scripts Python
  - Soluci√≥n de problemas comunes en Windows

### Scripts Disponibles

| Script Python (Multiplataforma) | Script Bash (Solo Linux) | Descripci√≥n |
|--------------------------------|--------------------------|-------------|
| `setup.py` | `setup.sh` | Configuraci√≥n inicial del entorno |
| `preprocess.py` | `preprocess.sh` | Preprocesamiento de datos |
| `train.py` | `train.sh` | Entrenamiento del modelo |
| `export.py` | `export.sh` | Exportaci√≥n a ONNX |
| `limpiar_audio.py` | - | Limpieza y normalizaci√≥n de audio |
| `validar_dataset.py` | - | Validaci√≥n de datasets |

**Recomendaci√≥n:** Usa los scripts de Python (`.py`) para mayor compatibilidad entre sistemas operativos. Los scripts bash (`.sh`) est√°n disponibles para usuarios de Linux que prefieran bash.

## üíª Requisitos del Sistema

### Hardware Recomendado

- **GPU** (opcional pero recomendado):
  - AMD Radeon RX 6000/7000 series con ROCm (Linux)
  - NVIDIA GeForce/RTX series con CUDA (Windows/Linux)
  - O entrenamiento con CPU (m√°s lento)
- **RAM**: 16GB m√≠nimo, 32GB recomendado
- **Almacenamiento**: 50GB+ de espacio libre
- **CPU**: Cualquier CPU moderna de 4+ n√∫cleos

### Software

- **SO**: 
  - Windows 10/11 (64-bit)
  - Ubuntu 20.04/22.04 LTS o similar
  - macOS 10.15+
- **Python**: 3.9+
- **Git**: Para clonar repositorios
- **ROCm**: 6.0+ (solo para GPU AMD en Linux)
- **CUDA**: 11.8+ (solo para GPU NVIDIA)
- **espeak-ng**: Para s√≠ntesis fon√©tica
  - Windows: [Descargar desde GitHub](https://github.com/espeak-ng/espeak-ng/releases)
  - Linux: `sudo apt-get install espeak-ng`
  - macOS: `brew install espeak-ng`

## üéì Recursos de Aprendizaje

### Datasets P√∫blicos en Espa√±ol

- [Common Voice (Mozilla)](https://commonvoice.mozilla.org/es) - Dataset colaborativo
- [M-AILABS](https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/) - Audiolibros
- [CSS10](https://github.com/Kyubyong/css10) - 10 idiomas incluyendo espa√±ol

### Enlaces √ötiles

- [Piper GitHub](https://github.com/rhasspy/piper) - Repositorio oficial
- [Piper Voices](https://huggingface.co/rhasspy/piper-voices) - Modelos pre-entrenados
- [ROCm Documentation](https://rocm.docs.amd.com/) - Documentaci√≥n de AMD

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìù Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- [Rhasspy](https://github.com/rhasspy) - Por crear Piper TTS
- [AMD](https://www.amd.com/) - Por ROCm y soporte de GPU
- Comunidad de c√≥digo abierto

## üí¨ Soporte

Si tienes preguntas o problemas:

1. Revisa la [GUIA_ENTRENAMIENTO.md](GUIA_ENTRENAMIENTO.md)
2. Busca en los [Issues](https://github.com/choruzo/entrenador-de-voz/issues)
3. Abre un nuevo Issue si no encuentras soluci√≥n
4. √önete al [Discord de Rhasspy](https://discord.gg/rhasspy)

## üìä Estado del Proyecto

üöß Proyecto en desarrollo activo - Nuevas caracter√≠sticas y mejoras en camino

---

Hecho con ‚ù§Ô∏è para la comunidad hispanohablante
