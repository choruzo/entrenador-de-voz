# üöÄ Entrenamiento en Google Colab

Este documento explica c√≥mo entrenar tu modelo de voz Piper TTS en Google Colab para aprovechar las GPUs gratuitas.

## üìã Requisitos Previos

1. **Cuenta de Google** (Gmail)
2. **Dataset preprocesado** o dataset crudo con:
   - `metadata.csv` (formato: `wavs/archivo.wav|Texto transcrito`)
   - `wavs/` (archivos de audio WAV)
   - `config.json` (configuraci√≥n del dataset)

## üéØ Ventajas de Entrenar en Colab

| Caracter√≠stica | CPU Local | Colab GPU (T4) | Colab GPU (A100) |
|---------------|-----------|----------------|------------------|
| **Tiempo por √©poca** | 30-60 min | 10-30 min | 3-10 min |
| **Costo** | Hardware propio | **Gratis*** | Colab Pro |
| **Configuraci√≥n** | Manual compleja | Autom√°tica | Autom√°tica |
| **VRAM disponible** | Variable | 15 GB | 40 GB |
| **Batch size** | 2-4 | 8-16 | 16-32 |

*L√≠mites: ~12 horas de sesi√≥n continua, reconectar para seguir

## üì§ Preparar Dataset para Colab

### Opci√≥n 1: Dataset Ya Preprocesado

Si ya ejecutaste `preprocess_dataset.sh` localmente:

```bash
# 1. Comprimir dataset preprocesado
cd ~/piper-training/datasets
zip -r sig_preprocessed.zip sig/

# 2. Subir a Google Drive
#    - Ir a https://drive.google.com
#    - Crear carpeta: piper-datasets/
#    - Subir sig_preprocessed.zip
#    - Extraer en Drive (click derecho ‚Üí Extraer)
```

### Opci√≥n 2: Dataset Crudo (se preprocesa en Colab)

```bash
# 1. Comprimir solo lo esencial
cd ~/piper-training/datasets
zip -r sig_raw.zip sig/metadata.csv sig/config.json sig/wavs/

# 2. Subir a Google Drive o subirlo directamente en Colab
```

## üöÄ Usar el Notebook de Colab

### Paso 1: Abrir en Colab

1. Subir `colab_piper_training.ipynb` a tu Google Drive
2. Hacer doble click en el archivo
3. Se abrir√° en Google Colaboratory

**O desde GitHub:**
1. Ir a: `https://colab.research.google.com`
2. File ‚Üí Upload notebook ‚Üí Seleccionar `colab_piper_training.ipynb`

### Paso 2: Configurar GPU

1. Runtime ‚Üí Change runtime type
2. Hardware accelerator: **GPU**
3. GPU type: **T4** (gratis) o **A100/V100** (Colab Pro)
4. Save

### Paso 3: Ejecutar Celdas

**Ejecutar en orden:**

```python
# 1Ô∏è‚É£ Verificar GPU
!nvidia-smi  # Debe mostrar una GPU NVIDIA

# 2Ô∏è‚É£ Instalar dependencias (5-10 min)
# Ejecutar todas las celdas de instalaci√≥n

# 3Ô∏è‚É£ Descargar modelo base (2-3 min)
# Se descarga en_US-lessac-high.ckpt (952 MB)

# 4Ô∏è‚É£ Configurar dataset
# AJUSTAR estas l√≠neas seg√∫n tu caso:
DRIVE_PATH = "/content/drive/MyDrive/piper-datasets/sig"  # ‚¨ÖÔ∏è Tu ruta en Drive
DATASET_DIR = "datasets/sig"  # ‚¨ÖÔ∏è Nombre del dataset

# 5Ô∏è‚É£ Entrenar
MAX_EPOCHS = 100      # ‚¨ÖÔ∏è Ajustar seg√∫n necesites
BATCH_SIZE = 16       # ‚¨ÖÔ∏è M√°s VRAM = m√°s batch size
CHECKPOINT_EPOCHS = 5 # Guardar cada 5 √©pocas

# 6Ô∏è‚É£ Monitorear
# Ver gr√°ficas de p√©rdidas en tiempo real

# 7Ô∏è‚É£ Exportar modelo
# Convierte checkpoint a ONNX

# 8Ô∏è‚É£ Descargar
# Guardar en Drive o descargar ZIP
```

## ‚öôÔ∏è Configuraciones Recomendadas

### GPU T4 (Gratis)
```python
BATCH_SIZE = 8-16
MAX_EPOCHS = 50-100
# Tiempo: ~10-30 min/√©poca
```

### GPU A100 (Colab Pro)
```python
BATCH_SIZE = 16-32
MAX_EPOCHS = 100-200
# Tiempo: ~3-10 min/√©poca
```

### Para datasets grandes (>1000 muestras)
```python
BATCH_SIZE = 16
VALIDATION_SPLIT = 0.1
CHECKPOINT_EPOCHS = 10  # Guardar menos frecuente
```

### Para datasets peque√±os (<500 muestras)
```python
BATCH_SIZE = 4-8
VALIDATION_SPLIT = 0.05
MAX_EPOCHS = 200+  # Necesita m√°s √©pocas
```

## üíæ Guardar Progreso

El notebook autom√°ticamente guarda:
- ‚úÖ Checkpoints cada N √©pocas en Drive
- ‚úÖ M√©tricas de entrenamiento (CSV)
- ‚úÖ Gr√°ficas de p√©rdidas
- ‚úÖ Modelo ONNX exportado

**Para sesiones largas:**
```python
# Ejecutar en una celda para guardar checkpoints en Drive
import shutil
from datetime import datetime

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
backup_dir = f"/content/drive/MyDrive/piper-checkpoints/backup_{timestamp}"
!mkdir -p "{backup_dir}"
!cp -r {DATASET_DIR}/lightning_logs "{backup_dir}/"
print(f"‚úÖ Backup guardado: {backup_dir}")
```

## üîÑ Continuar Entrenamiento Interrumpido

Si Colab se desconecta, puedes continuar:

```python
# En la celda de entrenamiento, cambiar:
--resume_from_checkpoint models_base/en_US-lessac-high.ckpt

# Por tu √∫ltimo checkpoint:
LAST_CHECKPOINT = "/content/drive/MyDrive/piper-checkpoints/backup_XXXXX/lightning_logs/version_0/checkpoints/epoch=49.ckpt"
!python -m piper_train \
  --resume_from_checkpoint "{LAST_CHECKPOINT}" \
  # ... resto de par√°metros
```

## üìä Interpretar M√©tricas

Durante el entrenamiento ver√°s:

```
Epoch 10: loss_gen_all=145.3, loss_disc_all=2.1
Epoch 20: loss_gen_all=98.7, loss_disc_all=1.8
Epoch 30: loss_gen_all=67.2, loss_disc_all=1.5
```

**Buenas se√±ales:**
- ‚úÖ `loss_gen_all` disminuye gradualmente
- ‚úÖ `loss_disc_all` se mantiene estable (1.0-3.0)
- ‚úÖ Sin mensajes de error o NaN

**Problemas:**
- ‚ùå P√©rdidas aumentan ‚Üí learning rate muy alto
- ‚ùå NaN o Inf ‚Üí normalizaci√≥n incorrecta del dataset
- ‚ùå P√©rdidas estancadas ‚Üí learning rate muy bajo o dataset muy peque√±o

## üéµ Probar Modelo Entrenado

Despu√©s de exportar:

```python
# En Colab
!pip install piper-tts
!echo "Hola, este es mi modelo entrenado" | piper \
    --model outputs/model.onnx \
    --config outputs/model.onnx.json \
    --output_file test.wav

from IPython.display import Audio
Audio('test.wav')
```

## üì• Descargar Resultados

El notebook genera:
```
model_trained.zip
‚îú‚îÄ‚îÄ model.onnx              # Modelo para usar con Piper
‚îú‚îÄ‚îÄ model.onnx.json         # Configuraci√≥n del modelo
‚îî‚îÄ‚îÄ checkpoint/
    ‚îî‚îÄ‚îÄ epoch=99.ckpt       # Checkpoint para continuar entrenamiento
```

**Usar el modelo descargado:**
```bash
# En tu computadora local
cd ~/Downloads
unzip model_trained.zip
echo "Prueba de voz" | piper --model model.onnx --output_file test.wav
```

## üêõ Soluci√≥n de Problemas

### Error: "Runtime disconnected"
**Causa:** Sesi√≥n inactiva >30 min  
**Soluci√≥n:** Ejecutar una celda cada 10-15 min, o usar Colab Pro

### Error: "CUDA out of memory"
**Soluci√≥n:** Reducir `BATCH_SIZE` (probar 8 ‚Üí 4 ‚Üí 2)

### Error: "Dataset not found"
**Soluci√≥n:** Verificar que `DRIVE_PATH` apunta a la ruta correcta en tu Drive

### Entrenamiento muy lento
**Verificar:**
```python
!nvidia-smi  # Debe mostrar GPU en uso
import torch
print(torch.cuda.is_available())  # Debe ser True
```

### P√©rdidas en NaN
**Causa:** Dataset mal preprocesado  
**Soluci√≥n:** Re-ejecutar preprocesamiento o verificar audio corrupto

## üí° Consejos y Trucos

1. **Usa Colab Pro** si entrenar√°s frecuentemente (GPU A100, sin l√≠mites)
2. **Guarda en Drive regularmente** - Colab puede desconectar sin aviso
3. **Monitorea uso de RAM/VRAM** con `!nvidia-smi` cada 10-15 min
4. **Batch size √≥ptimo:** Usa el m√°ximo que quepa en VRAM sin OOM
5. **No cierres la pesta√±a** - mantenla abierta aunque minimizada
6. **Activa notificaciones** para saber cuando termine el entrenamiento

## üìö Recursos Adicionales

- **Documentaci√≥n Piper:** https://github.com/rhasspy/piper/blob/master/TRAINING.md
- **Colab Tips:** https://colab.research.google.com/notebooks/pro.ipynb
- **Modelos pre-entrenados:** https://huggingface.co/rhasspy/piper-voices

---

## ‚è±Ô∏è Tiempos Estimados

**Dataset de 700 muestras:**
- Setup inicial: 5-10 min
- Por √©poca (T4): ~15 min
- Por √©poca (A100): ~5 min
- 100 √©pocas (T4): ~25 horas
- 100 √©pocas (A100): ~8 horas

**Estrategia recomendada:**
1. Entrenar 20-30 √©pocas en Colab
2. Probar calidad del modelo
3. Si es bueno, continuar 50-70 √©pocas m√°s
4. Exportar y descargar

---

¬øNecesitas ayuda? Revisa TROUBLESHOOTING.md o abre un issue en GitHub.
