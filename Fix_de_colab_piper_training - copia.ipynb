{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_cFDjrNjONc"
      },
      "source": [
        "# üéôÔ∏è Entrenamiento de Voz Piper TTS en Google Colab\n",
        "\n",
        "Este notebook permite entrenar modelos de voz Piper TTS con GPU gratuita de Google Colab.\n",
        "\n",
        "**GPU recomendada:** T4 o superior  \n",
        "**Tiempo por √©poca:** ~10-30 minutos con GPU (vs 30-60 min en CPU)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQP5qswijONf"
      },
      "source": [
        "## 1Ô∏è‚É£ Configuraci√≥n Inicial\n",
        "\n",
        "Verificar GPU y montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BGswX5isjONg",
        "outputId": "1f2ba339-2d50-4de7-aa5a-d360664c4508"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"nvidia-smi\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ PyTorch version: 2.8.0+cpu\n",
            "‚úÖ CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Verificar GPU disponible\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYlC-iRsjONi",
        "outputId": "fbab4da9-e7b2-4df4-dbb8-b921f12fc005"
      },
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Crear directorio de trabajo\n",
        "!mkdir -p /content/piper-training\n",
        "%cd /content/piper-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG5JPRb-jONi"
      },
      "source": [
        "## 2Ô∏è‚É£ Instalaci√≥n de Dependencias\n",
        "\n",
        "Instalar Piper y todas las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8afrK0_X0kak",
        "outputId": "38bdf0e4-5a45-41ab-fe0e-85e8b65681af"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfzlqSVg0zzJ",
        "outputId": "2ce40f1e-3add-4e17-a2d5-617835e72afb"
      },
      "outputs": [],
      "source": [
        "!conda create -n piper_env python=3.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqLRO6CgjONk",
        "outputId": "1db433cf-6beb-4c6b-d552-6ebe238ba6b1"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "echo \"üì¶ Instalando dependencias del sistema...\"\n",
        "apt-get update -qq\n",
        "apt-get install -y -qq espeak-ng wget git 2>&1 | grep -v \"debconf\"\n",
        "echo \"‚úÖ espeak-ng instalado\"\n",
        "espeak-ng --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKboFOmgjONl",
        "outputId": "83b73d26-e3bd-4f3b-df6a-0a8b3456fc6e"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "echo \"üì¶ Instalando piper-phonemize...\"\n",
        "cd /content/piper-training\n",
        "\n",
        "if [ ! -d \"piper_phonemize\" ]; then\n",
        "    echo \"Descargando piper-phonemize...\"\n",
        "    wget --show-progress \\\n",
        "        https://github.com/rhasspy/piper-phonemize/releases/download/2023.11.14-4/piper-phonemize_linux_x86_64.tar.gz \\\n",
        "        || { echo \"‚ùå Error descargando piper-phonemize\"; exit 1; }\n",
        "\n",
        "    echo \"Descomprimiendo...\"\n",
        "    tar -xzf piper-phonemize_linux_x86_64.tar.gz \\\n",
        "        || { echo \"‚ùå Error descomprimiendo piper-phonemize\"; exit 1; }\n",
        "\n",
        "    rm piper-phonemize_linux_x86_64.tar.gz\n",
        "    echo \"‚úÖ piper-phonemize instalado\"\n",
        "\n",
        "    # Verificar instalaci√≥n\n",
        "    if [ -d \"piper_phonemize\" ]; then\n",
        "        echo \"‚úÖ Directorio piper_phonemize creado correctamente\"\n",
        "        ls -la piper_phonemize/ | head -10\n",
        "    fi\n",
        "else\n",
        "    echo \"‚úÖ piper-phonemize ya existe\"\n",
        "    ls -la piper_phonemize/ | head -10\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCO3urYpjONm",
        "outputId": "038d477a-d69c-40e7-f9ad-9d62aca320c0"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "echo \"üì¶ Clonando Piper...\"\n",
        "if [ ! -d \"piper\" ]; then\n",
        "    git clone -q https://github.com/rhasspy/piper.git\n",
        "    echo \"‚úÖ Piper clonado\"\n",
        "else\n",
        "    echo \"‚úÖ Piper ya existe\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "ztyg64FtjONm",
        "outputId": "794f0649-f113-472e-b380-35f5310ca2c7"
      },
      "outputs": [],
      "source": [
        "# @title üì¶ INSTALACI√ìN DE DEPENDENCIAS (VERSI√ìN ESTABLE)\n",
        "# ‚ö†Ô∏è Esta celda instala TODO. NO reinicies el runtime despu√©s.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"üì¶ CONFIGURANDO ENTORNO PARA PIPER-TRAINING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Ir al directorio de trabajo\n",
        "%cd /content/piper-training\n",
        "\n",
        "# 0. CLONAR PIPER SI NO EXISTE\n",
        "if not os.path.exists(\"/content/piper-training/piper\"):\n",
        "    print(\"üì• Clonando repositorio piper...\")\n",
        "    !git clone -q https://github.com/rhasspy/piper.git\n",
        "    print(\"   ‚úÖ Piper clonado\")\n",
        "else:\n",
        "    print(\"‚úÖ Piper ya existe\")\n",
        "\n",
        "piper_python_dir = \"/content/piper-training/piper/src/python\"\n",
        "\n",
        "if not os.path.exists(piper_python_dir):\n",
        "    print(\"‚ùå ERROR: piper/src/python no existe\")\n",
        "    raise SystemExit()\n",
        "\n",
        "# 1. Degradar pip\n",
        "print(\"üîß Ajustando pip...\")\n",
        "!pip install --quiet \"pip<24.1\"\n",
        "\n",
        "# 2. Instalar pytorch-lightning\n",
        "print(\"üì¶ Instalando pytorch-lightning 1.7...\")\n",
        "!pip install --quiet \"pytorch-lightning>=1.7.0,<1.8.0\"\n",
        "\n",
        "# 3. Instalar piper-phonemize\n",
        "print(\"üì¶ Instalando piper-phonemize...\")\n",
        "!pip install --quiet piper-phonemize==1.1.0\n",
        "\n",
        "# 4. Instalar numpy y scipy\n",
        "print(\"üì¶ Instalando numpy/scipy...\")\n",
        "!pip install --quiet \"numpy<2.0.0\" \"scipy==1.11.4\"\n",
        "\n",
        "# 5. Instalar monotonic_align\n",
        "print(\"üì¶ Instalando monotonic_align...\")\n",
        "!pip install --quiet git+https://github.com/resemble-ai/monotonic_align.git\n",
        "\n",
        "# 6. Copiar monotonic_align al directorio de piper\n",
        "print(\"üîß Copiando monotonic_align a piper...\")\n",
        "!cp -r /usr/local/lib/python3.11/site-packages/monotonic_align {piper_python_dir}/\n",
        "print(\"   ‚úÖ Copiado\")\n",
        "\n",
        "# 7. PARCHEAR el __init__.py\n",
        "print(\"üîß Parcheando piper_train...\")\n",
        "init_file = f\"{piper_python_dir}/piper_train/vits/monotonic_align/__init__.py\"\n",
        "\n",
        "new_init_content = '''\"\"\"Monotonic alignment search\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "_current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "_piper_python_dir = os.path.dirname(os.path.dirname(os.path.dirname(_current_dir)))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "if _piper_python_dir not in sys.path:\n",
        "    sys.path.append(_piper_python_dir)\n",
        "\n",
        "from monotonic_align.core import maximum_path_c\n",
        "\n",
        "def maximum_path(neg_cent, mask):\n",
        "    device = neg_cent.device\n",
        "    dtype = neg_cent.dtype\n",
        "    neg_cent = neg_cent.data.cpu().numpy().astype(np.float32)\n",
        "    path = np.zeros(neg_cent.shape, dtype=np.int32)\n",
        "    t_t_max = mask.sum(1)[:, 0].data.cpu().numpy().astype(np.int32)\n",
        "    t_s_max = mask.sum(2)[:, 0].data.cpu().numpy().astype(np.int32)\n",
        "    maximum_path_c(path, neg_cent, t_t_max, t_s_max)\n",
        "    return torch.from_numpy(path).to(device=device, dtype=dtype)\n",
        "'''\n",
        "\n",
        "with open(init_file, 'w') as f:\n",
        "    f.write(new_init_content)\n",
        "print(\"   ‚úÖ Parche aplicado\")\n",
        "\n",
        "# 8. Instalar piper-train\n",
        "print(\"üõ†Ô∏è Instalando piper-train...\")\n",
        "%cd {piper_python_dir}\n",
        "!pip install --quiet --no-deps -e .\n",
        "\n",
        "# 9. Volver al directorio principal\n",
        "%cd /content/piper-training\n",
        "os.environ['LD_LIBRARY_PATH'] = f\"/content/piper-training/piper_phonemize/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ INSTALACI√ìN COMPLETADA\")\n",
        "print(\"\\n‚ö° EJECUTA LA SIGUIENTE CELDA PARA VERIFICAR\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuxXrwXUjONn",
        "outputId": "872b7048-263c-4510-f83f-2e236f5ee16d"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ VERIFICACI√ìN DEL ENTORNO\n",
        "# Esta celda verifica y reinstala si es necesario\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Reinstalar paquetes que pueden perderse entre celdas\n",
        "print(\"üì¶ Verificando paquetes...\")\n",
        "!pip install --quiet \"pip<24.1\" 2>/dev/null\n",
        "!pip install --quiet \"pytorch-lightning>=1.7.0,<1.8.0\" 2>/dev/null\n",
        "!pip install --quiet \"numpy<2.0.0\" \"scipy==1.11.4\" 2>/dev/null\n",
        "\n",
        "# Configurar LD_LIBRARY_PATH\n",
        "os.environ['LD_LIBRARY_PATH'] = f\"/content/piper-training/piper_phonemize/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "\n",
        "# Verificar PyTorch\n",
        "import torch\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CUDA no disponible - el entrenamiento ser√° muy lento\")\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"scipy: {scipy.__version__}\")\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "print(f\"pytorch-lightning: {pl.__version__}\")\n",
        "\n",
        "# Verificar piper_train\n",
        "print(\"\\nüîç M√≥dulos piper_train:\")\n",
        "try:\n",
        "    import piper_train\n",
        "    print(\"‚úÖ piper_train\")\n",
        "    from piper_train.vits import commons\n",
        "    print(\"‚úÖ piper_train.vits\")\n",
        "    from piper_train.vits.monotonic_align import maximum_path\n",
        "    print(\"‚úÖ monotonic_align.maximum_path\")\n",
        "    \n",
        "    # Test\n",
        "    test_neg = torch.randn(1, 10, 20)\n",
        "    test_mask = torch.ones(1, 10, 20)\n",
        "    result = maximum_path(test_neg, test_mask)\n",
        "    print(f\"‚úÖ Test: shape={result.shape}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"‚úÖ TODO LISTO - Puedes continuar al entrenamiento\")\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"‚ö†Ô∏è NOTA: Sin GPU el entrenamiento ser√° MUY lento\")\n",
        "    print(\"=\" * 50)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZstNq5RjONn"
      },
      "source": [
        "## 3Ô∏è‚É£ Descargar Modelo Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIpJiVo3jONn",
        "outputId": "2619c105-f27a-4d63-a4fc-8df380e97747"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "mkdir -p models_base && cd models_base\n",
        "if [ ! -f \"en_US-lessac-high.ckpt\" ]; then\n",
        "    echo \"üì• Descargando checkpoint (952 MB)...\"\n",
        "    wget -q --show-progress \\\n",
        "        \"https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/7bf647cb000d8c8319c6cdd4289dd6b7d0d3eeb8/en/en_US/lessac/high/epoch=2218-step=838782.ckpt\" \\\n",
        "        -O en_US-lessac-high.ckpt\n",
        "    echo \"‚úÖ Checkpoint descargado\"\n",
        "else\n",
        "    echo \"‚úÖ Checkpoint ya existe\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrtUUtcvjONo"
      },
      "source": [
        "## 4Ô∏è‚É£ Configurar Dataset\n",
        "\n",
        "Sube tu dataset preprocesado o procesa uno nuevo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f4skKe7jONo",
        "outputId": "3d4ffe32-b2a1-4573-851e-91c9010204df"
      },
      "outputs": [],
      "source": [
        "# OPCI√ìN A: Copiar desde Google Drive\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/sig\"  # ‚¨ÖÔ∏è AJUSTAR\n",
        "\n",
        "!mkdir -p datasets\n",
        "!cp -r \"{DRIVE_PATH}\" datasets/\n",
        "import os\n",
        "DATASET_NAME = os.path.basename(DRIVE_PATH)\n",
        "DATASET_DIR = f\"datasets/{DATASET_NAME}\"\n",
        "print(f\"‚úÖ Dataset copiado: {DATASET_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQBm5xFgjONo"
      },
      "outputs": [],
      "source": [
        "# OPCI√ìN B: Subir ZIP y preprocesar\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Sube tu dataset.zip aqu√≠"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olImVywbjONo"
      },
      "outputs": [],
      "source": [
        "# OPCI√ìN C: Preprocesar dataset directamente en Colab\n",
        "# Si subes un ZIP con formato LJSpeech (wavs/ y metadata.csv)\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Descomprimir dataset\n",
        "zip_file = \"dataset.zip\"  # ‚¨ÖÔ∏è Nombre del archivo subido\n",
        "if os.path.exists(zip_file):\n",
        "    print(f\"üì¶ Descomprimiendo {zip_file}...\")\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"datasets/raw\")\n",
        "\n",
        "    # Preprocesar dataset\n",
        "    RAW_DIR = \"datasets/raw/mi_dataset\"  # ‚¨ÖÔ∏è AJUSTAR nombre\n",
        "    PROCESSED_DIR = \"datasets/sig\"\n",
        "    LANGUAGE = \"es-es\"  # ‚¨ÖÔ∏è AJUSTAR idioma\n",
        "\n",
        "    print(f\"‚öôÔ∏è Preprocesando dataset...\")\n",
        "    !python -m piper_train.preprocess \\\n",
        "      --language {LANGUAGE} \\\n",
        "      --input-dir {RAW_DIR} \\\n",
        "      --output-dir {PROCESSED_DIR} \\\n",
        "      --single-speaker \\\n",
        "      --sample-rate 22050\n",
        "\n",
        "    DATASET_DIR = PROCESSED_DIR\n",
        "    print(f\"‚úÖ Dataset preprocesado: {DATASET_DIR}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ dataset.zip, aseg√∫rate de subirlo primero\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-0zf4lDjONo"
      },
      "source": [
        "### üìã Verificar Dataset\n",
        "\n",
        "Antes de entrenar, verifica la estructura del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OES8ekq5jONo",
        "outputId": "d3ac7bb4-fb2b-4f3e-9257-f5c6f94e7192"
      },
      "outputs": [],
      "source": [
        "# Verificar estructura del dataset\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "DATASET_DIR = \"datasets/sig\"  # ‚¨ÖÔ∏è AJUSTAR si es necesario\n",
        "dataset_path = Path(DATASET_DIR)\n",
        "\n",
        "print(\"üîç Verificando dataset...\\n\")\n",
        "\n",
        "# Verificar archivos requeridos\n",
        "required_files = ['config.json', 'dataset.jsonl']\n",
        "for file in required_files:\n",
        "    file_path = dataset_path / file\n",
        "    if file_path.exists():\n",
        "        print(f\"‚úÖ {file}\")\n",
        "        if file == 'config.json':\n",
        "            with open(file_path, 'r') as f:\n",
        "                config = json.load(f)\n",
        "                print(f\"   - Audio: {config.get('audio', {}).get('sample_rate')} Hz\")\n",
        "                print(f\"   - Idioma: {config.get('espeak', {}).get('voice')}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {file} no encontrado\")\n",
        "\n",
        "# Contar muestras\n",
        "jsonl_path = dataset_path / 'dataset.jsonl'\n",
        "if jsonl_path.exists():\n",
        "    with open(jsonl_path, 'r') as f:\n",
        "        num_samples = sum(1 for _ in f)\n",
        "    print(f\"\\nüìä Total de muestras: {num_samples}\")\n",
        "\n",
        "    # Calcular duraci√≥n aproximada de entrenamiento\n",
        "    samples_per_epoch = num_samples\n",
        "    time_per_sample = 0.3  # segundos aproximados por muestra en GPU T4\n",
        "    time_per_epoch = (samples_per_epoch * time_per_sample) / 60\n",
        "    print(f\"‚è±Ô∏è Tiempo estimado por √©poca: ~{time_per_epoch:.1f} minutos (GPU T4)\")\n",
        "else:\n",
        "    print(\"‚ùå No se pudo contar muestras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELh9zJo_jONp"
      },
      "source": [
        "## 5Ô∏è‚É£ Entrenar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY9RgM0LjONp",
        "outputId": "cd9fc90f-4d2e-49db-92ae-cd9b8de5f314"
      },
      "outputs": [],
      "source": [
        "# Configuraci√≥n de entrenamiento\n",
        "DATASET_DIR = \"datasets/sig\"  # ‚¨ÖÔ∏è AJUSTAR\n",
        "MAX_EPOCHS = 100\n",
        "BATCH_SIZE = 16  # Ajustar seg√∫n VRAM disponible\n",
        "CHECKPOINT_EPOCHS = 5\n",
        "VALIDATION_SPLIT = 0.05\n",
        "NUM_TEST_EXAMPLES = 0\n",
        "PRECISION = \"32\"  # Usar \"32\" para mejor compatibilidad\n",
        "\n",
        "# Entrenar modelo con piper_train\n",
        "!python -m piper_train \\\n",
        "  --dataset-dir {DATASET_DIR} \\\n",
        "  --accelerator gpu \\\n",
        "  --devices 1 \\\n",
        "  --batch-size {BATCH_SIZE} \\\n",
        "  --validation-split {VALIDATION_SPLIT} \\\n",
        "  --num-test-examples {NUM_TEST_EXAMPLES} \\\n",
        "  --max_epochs {MAX_EPOCHS} \\\n",
        "  --resume_from_checkpoint models_base/en_US-lessac-high.ckpt \\\n",
        "  --checkpoint-epochs {CHECKPOINT_EPOCHS} \\\n",
        "  --precision {PRECISION}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qMnCsU7jONp"
      },
      "source": [
        "### ‚öôÔ∏è Configuraci√≥n Avanzada\n",
        "\n",
        "Ajusta estos par√°metros seg√∫n tu caso:\n",
        "\n",
        "- **BATCH_SIZE**:\n",
        "  - 16-32 para T4 (16GB)\n",
        "  - 8-16 para GPUs con menos VRAM\n",
        "  - Reduce si obtienes errores de memoria\n",
        "  \n",
        "- **MAX_EPOCHS**:\n",
        "  - M√≠nimo 100 para resultados aceptables\n",
        "  - 500-1000+ para mejor calidad\n",
        "  \n",
        "- **CHECKPOINT_EPOCHS**: Cada cu√°ntas √©pocas guardar un checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui3KfI-cjONp"
      },
      "source": [
        "## 6Ô∏è‚É£ Monitorear Progreso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKuCfWkKjONp"
      },
      "outputs": [],
      "source": [
        "# Monitorear el progreso durante el entrenamiento\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def monitor_training(dataset_dir, update_interval=30):\n",
        "    \"\"\"\n",
        "    Monitorea el entrenamiento en tiempo real\n",
        "\n",
        "    Args:\n",
        "        dataset_dir: Directorio del dataset\n",
        "        update_interval: Segundos entre actualizaciones\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    from pathlib import Path\n",
        "\n",
        "    logs_dir = Path(dataset_dir) / \"lightning_logs\"\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # Buscar √∫ltima versi√≥n\n",
        "            versions = sorted(logs_dir.glob(\"version_*\"))\n",
        "            if not versions:\n",
        "                print(\"‚è≥ Esperando inicio del entrenamiento...\")\n",
        "                time.sleep(update_interval)\n",
        "                continue\n",
        "\n",
        "            metrics_file = versions[-1] / \"metrics.csv\"\n",
        "            if metrics_file.exists():\n",
        "                df = pd.read_csv(metrics_file)\n",
        "\n",
        "                print(\"=\" * 60)\n",
        "                print(\"üìä PROGRESO DEL ENTRENAMIENTO\")\n",
        "                print(\"=\" * 60)\n",
        "                print(f\"\\n√âpoca actual: {int(df['epoch'].max())}\")\n",
        "                print(f\"Total de pasos: {int(df['step'].max())}\")\n",
        "                print(f\"\\n--- √öltimas 5 m√©tricas ---\")\n",
        "                print(df[['epoch', 'loss_gen_all', 'loss_disc_all']].tail())\n",
        "                print(\"\\nüí° Presiona el bot√≥n STOP para detener el monitoreo\")\n",
        "\n",
        "            time.sleep(update_interval)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n‚úÖ Monitoreo detenido\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error: {e}\")\n",
        "            time.sleep(update_interval)\n",
        "\n",
        "# Para iniciar el monitoreo (ejecutar en otra celda mientras entrena):\n",
        "# monitor_training(DATASET_DIR, update_interval=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy63qU63jONq"
      },
      "outputs": [],
      "source": [
        "# Ver m√©tricas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
        "versions = sorted(logs_dir.glob(\"version_*\"))\n",
        "if versions:\n",
        "    metrics = versions[-1] / \"metrics.csv\"\n",
        "    if metrics.exists():\n",
        "        df = pd.read_csv(metrics)\n",
        "        print(df.tail())\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(df['epoch'], df['loss_gen_all'])\n",
        "        plt.title('Generator Loss')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(df['epoch'], df['loss_disc_all'])\n",
        "        plt.title('Discriminator Loss')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9McphIWjONq"
      },
      "source": [
        "## 7Ô∏è‚É£ Exportar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc9aeV-IjONq"
      },
      "outputs": [],
      "source": [
        "# Exportar a ONNX\n",
        "from pathlib import Path\n",
        "\n",
        "# Buscar el √∫ltimo checkpoint\n",
        "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
        "versions = sorted(logs_dir.glob(\"version_*\"))\n",
        "\n",
        "if not versions:\n",
        "    print(\"‚ùå No se encontraron versiones de entrenamiento\")\n",
        "else:\n",
        "    latest_version = versions[-1]\n",
        "    checkpoints = sorted(latest_version.glob(\"checkpoints/*.ckpt\"))\n",
        "\n",
        "    if not checkpoints:\n",
        "        print(\"‚ùå No se encontraron checkpoints\")\n",
        "    else:\n",
        "        CHECKPOINT = str(checkpoints[-1])\n",
        "        print(f\"üì¶ Exportando checkpoint: {CHECKPOINT}\")\n",
        "\n",
        "        # Crear directorio de salida\n",
        "        !mkdir -p outputs\n",
        "\n",
        "        # Exportar a ONNX usando el m√≥dulo correcto\n",
        "        !python3 -m piper_train.export_onnx \\\n",
        "            \"{CHECKPOINT}\" \\\n",
        "            \"/content/piper-training/outputs/model.onnx\"\n",
        "\n",
        "        # Copiar archivo de configuraci√≥n JSON\n",
        "        config_src = Path(DATASET_DIR) / \"config.json\"\n",
        "        if config_src.exists():\n",
        "            !cp \"{config_src}\" outputs/model.onnx.json\n",
        "            print(\"‚úÖ Modelo exportado a outputs/\")\n",
        "            print(f\"   - model.onnx\")\n",
        "            print(f\"   - model.onnx.json\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No se encontr√≥ config.json en el dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLnsV7hpjONq"
      },
      "source": [
        "## 8Ô∏è‚É£ Descargar Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoS8iuasjONq"
      },
      "outputs": [],
      "source": [
        "# Guardar en Google Drive\n",
        "!mkdir -p \"/content/drive/MyDrive/piper-models/trained_model\"\n",
        "!cp -r outputs/* \"/content/drive/MyDrive/piper-models/trained_model/\"\n",
        "print(\"‚úÖ Guardado en Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fid5NP1OjONr"
      },
      "outputs": [],
      "source": [
        "# O descargar directamente\n",
        "from google.colab import files\n",
        "!zip -r model_trained.zip outputs/\n",
        "files.download(\"model_trained.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrCanJOsjONr"
      },
      "source": [
        "## 9Ô∏è‚É£ Probar el Modelo\n",
        "\n",
        "Prueba tu modelo entrenado directamente en Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni7VCOj-jONr"
      },
      "outputs": [],
      "source": [
        "# Instalar piper-tts para pruebas\n",
        "!pip install -q piper-tts\n",
        "\n",
        "# Generar audio de prueba\n",
        "TEST_TEXT = \"Hola, esta es una prueba de mi voz personalizada con Piper TTS.\"\n",
        "OUTPUT_WAV = \"prueba.wav\"\n",
        "\n",
        "!echo \"{TEST_TEXT}\" | piper --model outputs/model.onnx --output_file {OUTPUT_WAV}\n",
        "\n",
        "# Reproducir audio\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "if os.path.exists(OUTPUT_WAV):\n",
        "    print(\"‚úÖ Audio generado exitosamente\")\n",
        "    display(Audio(OUTPUT_WAV, autoplay=False))\n",
        "else:\n",
        "    print(\"‚ùå No se pudo generar el audio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny0Jw51hjONr"
      },
      "source": [
        "## üîü Soluci√≥n de Problemas\n",
        "\n",
        "### Errores comunes y soluciones:\n",
        "\n",
        "**1. Error de memoria GPU (CUDA out of memory)**\n",
        "- Reduce `BATCH_SIZE` (prueba con 8, 4, o incluso 2)\n",
        "- Cierra otras celdas que usen GPU\n",
        "- Reinicia el runtime: `Runtime > Restart runtime`\n",
        "\n",
        "**2. Error \"No module named 'piper_train'\"**\n",
        "- Verifica que ejecutaste la celda de instalaci√≥n de dependencias\n",
        "- Aseg√∫rate de estar en el directorio correcto\n",
        "\n",
        "**3. Dataset vac√≠o o sin muestras**\n",
        "- Verifica que `dataset.jsonl` tenga contenido\n",
        "- Revisa que los archivos de audio est√©n en el formato correcto\n",
        "- Ejecuta la celda de verificaci√≥n de dataset\n",
        "\n",
        "**4. P√©rdidas (losses) no disminuyen**\n",
        "- Es normal al principio del entrenamiento\n",
        "- Espera al menos 50-100 √©pocas antes de evaluar\n",
        "- Verifica que el modelo base sea compatible con tu idioma\n",
        "\n",
        "**5. Entrenamiento muy lento**\n",
        "- Verifica que est√©s usando GPU: `Runtime > Change runtime type > GPU`\n",
        "- Comprueba disponibilidad con `!nvidia-smi`\n",
        "- GPU T4 es recomendada para mejor rendimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWKIQPf7jONr"
      },
      "source": [
        "## üßπ Limpieza (Opcional)\n",
        "\n",
        "Libera espacio eliminando archivos temporales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a15V8RPajONs"
      },
      "outputs": [],
      "source": [
        "# Eliminar archivos temporales para liberar espacio\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üßπ Limpiando archivos temporales...\\n\")\n",
        "\n",
        "# Eliminar logs antiguos (mantener solo el √∫ltimo)\n",
        "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
        "if logs_dir.exists():\n",
        "    versions = sorted(logs_dir.glob(\"version_*\"))\n",
        "    if len(versions) > 1:\n",
        "        for old_version in versions[:-1]:\n",
        "            shutil.rmtree(old_version)\n",
        "            print(f\"‚úÖ Eliminado: {old_version.name}\")\n",
        "\n",
        "# Eliminar checkpoints intermedios (mantener solo cada 10 √©pocas)\n",
        "if versions:\n",
        "    checkpoints_dir = versions[-1] / \"checkpoints\"\n",
        "    if checkpoints_dir.exists():\n",
        "        checkpoints = sorted(checkpoints_dir.glob(\"*.ckpt\"))\n",
        "        for ckpt in checkpoints[:-1]:  # Mantener el √∫ltimo\n",
        "            epoch = ckpt.stem.split('-')[0].replace('epoch=', '')\n",
        "            if epoch.isdigit() and int(epoch) % 10 != 0:\n",
        "                ckpt.unlink()\n",
        "                print(f\"‚úÖ Eliminado checkpoint: {ckpt.name}\")\n",
        "\n",
        "# Verificar espacio disponible\n",
        "total, used, free = shutil.disk_usage(\"/\")\n",
        "print(f\"\\nüíæ Espacio disponible: {free // (2**30)} GB\")\n",
        "print(\"‚úÖ Limpieza completada\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
