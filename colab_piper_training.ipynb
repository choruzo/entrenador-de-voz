{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Entrenamiento de Voz Piper TTS en Google Colab\n",
    "\n",
    "Este notebook permite entrenar modelos de voz Piper TTS con GPU gratuita de Google Colab.\n",
    "\n",
    "**GPU recomendada:** T4 o superior  \n",
    "**Tiempo por √©poca:** ~10-30 minutos con GPU (vs 30-60 min en CPU)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuraci√≥n Inicial\n",
    "\n",
    "Verificar GPU y montar Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/javie/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Crear directorio de trabajo\n",
    "!mkdir -p /content/piper-training\n",
    "%cd /content/piper-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Instalaci√≥n de Dependencias\n",
    "\n",
    "Instalar Piper y todas las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "echo \"üì¶ Instalando dependencias del sistema...\"\n",
    "apt-get update -qq\n",
    "apt-get install -y -qq espeak-ng wget git 2>&1 | grep -v \"debconf\"\n",
    "echo \"‚úÖ espeak-ng instalado\"\n",
    "espeak-ng --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"üì¶ Instalando piper-phonemize...\"\n",
    "cd /content/piper-training\n",
    "\n",
    "if [ ! -d \"piper_phonemize\" ]; then\n",
    "    echo \"Descargando piper-phonemize...\"\n",
    "    wget --show-progress \\\n",
    "        https://github.com/rhasspy/piper-phonemize/releases/download/2023.11.14-4/piper-phonemize_linux_x86_64.tar.gz \\\n",
    "        || { echo \"‚ùå Error descargando piper-phonemize\"; exit 1; }\n",
    "    \n",
    "    echo \"Descomprimiendo...\"\n",
    "    tar -xzf piper-phonemize_linux_x86_64.tar.gz \\\n",
    "        || { echo \"‚ùå Error descomprimiendo piper-phonemize\"; exit 1; }\n",
    "    \n",
    "    rm piper-phonemize_linux_x86_64.tar.gz\n",
    "    echo \"‚úÖ piper-phonemize instalado\"\n",
    "    \n",
    "    # Verificar instalaci√≥n\n",
    "    if [ -d \"piper_phonemize\" ]; then\n",
    "        echo \"‚úÖ Directorio piper_phonemize creado correctamente\"\n",
    "        ls -la piper_phonemize/ | head -10\n",
    "    fi\n",
    "else\n",
    "    echo \"‚úÖ piper-phonemize ya existe\"\n",
    "    ls -la piper_phonemize/ | head -10\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "echo \"üì¶ Clonando Piper...\"\n",
    "if [ ! -d \"piper\" ]; then\n",
    "    git clone -q https://github.com/rhasspy/piper.git\n",
    "    echo \"‚úÖ Piper clonado\"\n",
    "else\n",
    "    echo \"‚úÖ Piper ya existe\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è EJECUTAR ESTA CELDA Y LUEGO REINICIAR EL RUNTIME\n",
    "# Despu√©s de completar, ve a: Runtime > Restart session\n",
    "# Luego ejecuta la siguiente celda de verificaci√≥n\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì¶ INSTALACI√ìN DE DEPENDENCIAS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚ö†Ô∏è Al finalizar, REINICIA el runtime:\")\n",
    "print(\"   Runtime > Restart session\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Bajar versi√≥n de pip\n",
    "print(\"üì¶ Ajustando pip...\")\n",
    "!pip install --quiet pip==24.0\n",
    "\n",
    "# Instalar PyTorch con CUDA 12.1\n",
    "print(\"\\nüì¶ Instalando PyTorch 2.2.0...\")\n",
    "!pip install --quiet torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Instalar dependencias\n",
    "print(\"\\nüì¶ Instalando dependencias...\")\n",
    "!pip install --quiet \"pytorch-lightning>=1.9.0,<2.0.0\"\n",
    "!pip install --quiet \"librosa>=0.9.0\"\n",
    "!pip install --quiet \"onnxruntime>=1.10.0\"\n",
    "!pip install --quiet \"cython>=0.29.0\"\n",
    "!pip install --quiet \"pydantic>=1.10.0,<2.0\"\n",
    "!pip install --quiet \"onnx>=1.11.0\"\n",
    "\n",
    "# Configurar piper-phonemize\n",
    "print(\"\\nüì¶ Configurando piper-phonemize...\")\n",
    "phonemize_lib = \"/content/piper-training/piper_phonemize/lib\"\n",
    "if Path(phonemize_lib).exists():\n",
    "    print(f\"‚úÖ Binarios encontrados\")\n",
    "else:\n",
    "    for so_file in Path(\"/content/piper-training\").rglob(\"libpiper_phonemize.so*\"):\n",
    "        phonemize_lib = str(so_file.parent)\n",
    "        break\n",
    "\n",
    "# Guardar config en archivo para despu√©s del reinicio\n",
    "config_file = \"/content/piper-training/.piper_config\"\n",
    "with open(config_file, 'w') as f:\n",
    "    f.write(f\"PHONEMIZE_LIB={phonemize_lib}\\n\")\n",
    "    f.write(f\"PIPER_PYTHON=/content/piper-training/piper/src/python\\n\")\n",
    "print(f\"‚úÖ Configuraci√≥n guardada\")\n",
    "\n",
    "# Instalar piper_train\n",
    "print(\"\\nüì¶ Instalando piper_train...\")\n",
    "piper_python_dir = \"/content/piper-training/piper/src/python\"\n",
    "%cd {piper_python_dir}\n",
    "!pip install --quiet -e . --no-deps\n",
    "%cd /content/piper-training\n",
    "\n",
    "# Forzar numpy y scipy correctos AL FINAL\n",
    "print(\"\\nüì¶ Instalando numpy 1.26.4 y scipy 1.11.4...\")\n",
    "!pip uninstall -y numpy scipy 2>/dev/null\n",
    "!pip install --quiet --force-reinstall \"numpy==1.26.4\"\n",
    "!pip install --quiet --force-reinstall \"scipy==1.11.4\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ INSTALACI√ìN COMPLETADA\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANTE: Ahora REINICIA el runtime:\")\n",
    "print(\"   Ve a: Runtime > Restart session\")\n",
    "print(\"   Luego ejecuta la SIGUIENTE CELDA para verificar\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ EJECUTAR DESPU√âS DE REINICIAR EL RUNTIME\n",
    "# Esta celda configura el entorno y verifica la instalaci√≥n\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîÑ Configurando entorno despu√©s del reinicio...\\n\")\n",
    "\n",
    "# Leer configuraci√≥n guardada\n",
    "config_file = \"/content/piper-training/.piper_config\"\n",
    "config = {}\n",
    "if Path(config_file).exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        for line in f:\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            config[key] = value\n",
    "\n",
    "# Configurar variables de entorno\n",
    "phonemize_lib = config.get('PHONEMIZE_LIB', '/content/piper-training/piper_phonemize/lib')\n",
    "piper_python = config.get('PIPER_PYTHON', '/content/piper-training/piper/src/python')\n",
    "\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"{phonemize_lib}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "os.environ['PATH'] = f\"{phonemize_lib}:{os.environ.get('PATH', '')}\"\n",
    "os.environ['PYTHONPATH'] = f\"{piper_python}:{os.environ.get('PYTHONPATH', '')}\"\n",
    "sys.path.insert(0, piper_python)\n",
    "\n",
    "# Cambiar al directorio de trabajo\n",
    "%cd /content/piper-training\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(\"üîç VERIFICACI√ìN DEL ENTORNO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "print(f\"\\nnumpy: {np.__version__}\")\n",
    "print(f\"scipy: {scipy.__version__}\")\n",
    "\n",
    "# Verificar piper_train\n",
    "print(\"\\nüîç M√≥dulos piper_train:\")\n",
    "try:\n",
    "    import piper_train\n",
    "    print(\"‚úÖ piper_train\")\n",
    "    from piper_train import vits\n",
    "    print(\"‚úÖ piper_train.vits\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Verificaci√≥n final\n",
    "if np.__version__.startswith(\"1.26\") and scipy.__version__.startswith(\"1.11\"):\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"‚úÖ ENTORNO LISTO PARA ENTRENAR\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Las versiones no son correctas.\")\n",
    "    print(\"   Ejecuta la celda anterior y reinicia el runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Descargar Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "mkdir -p models_base && cd models_base\n",
    "if [ ! -f \"en_US-lessac-high.ckpt\" ]; then\n",
    "    echo \"üì• Descargando checkpoint (952 MB)...\"\n",
    "    wget -q --show-progress \\\n",
    "        \"https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/7bf647cb000d8c8319c6cdd4289dd6b7d0d3eeb8/en/en_US/lessac/high/epoch=2218-step=838782.ckpt\" \\\n",
    "        -O en_US-lessac-high.ckpt\n",
    "    echo \"‚úÖ Checkpoint descargado\"\n",
    "else\n",
    "    echo \"‚úÖ Checkpoint ya existe\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Configurar Dataset\n",
    "\n",
    "Sube tu dataset preprocesado o procesa uno nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCI√ìN A: Copiar desde Google Drive\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/sig\"  # ‚¨ÖÔ∏è AJUSTAR\n",
    "\n",
    "!mkdir -p datasets\n",
    "!cp -r \"{DRIVE_PATH}\" datasets/\n",
    "import os\n",
    "DATASET_NAME = os.path.basename(DRIVE_PATH)\n",
    "DATASET_DIR = f\"datasets/{DATASET_NAME}\"\n",
    "print(f\"‚úÖ Dataset copiado: {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCI√ìN B: Subir ZIP y preprocesar\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Sube tu dataset.zip aqu√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCI√ìN C: Preprocesar dataset directamente en Colab\n",
    "# Si subes un ZIP con formato LJSpeech (wavs/ y metadata.csv)\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Descomprimir dataset\n",
    "zip_file = \"dataset.zip\"  # ‚¨ÖÔ∏è Nombre del archivo subido\n",
    "if os.path.exists(zip_file):\n",
    "    print(f\"üì¶ Descomprimiendo {zip_file}...\")\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"datasets/raw\")\n",
    "    \n",
    "    # Preprocesar dataset\n",
    "    RAW_DIR = \"datasets/raw/mi_dataset\"  # ‚¨ÖÔ∏è AJUSTAR nombre\n",
    "    PROCESSED_DIR = \"datasets/sig\"\n",
    "    LANGUAGE = \"es-es\"  # ‚¨ÖÔ∏è AJUSTAR idioma\n",
    "    \n",
    "    print(f\"‚öôÔ∏è Preprocesando dataset...\")\n",
    "    !python -m piper_train.preprocess \\\n",
    "      --language {LANGUAGE} \\\n",
    "      --input-dir {RAW_DIR} \\\n",
    "      --output-dir {PROCESSED_DIR} \\\n",
    "      --single-speaker \\\n",
    "      --sample-rate 22050\n",
    "    \n",
    "    DATASET_DIR = PROCESSED_DIR\n",
    "    print(f\"‚úÖ Dataset preprocesado: {DATASET_DIR}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ dataset.zip, aseg√∫rate de subirlo primero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã Verificar Dataset\n",
    "\n",
    "Antes de entrenar, verifica la estructura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar estructura del dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_DIR = \"datasets/sig\"  # ‚¨ÖÔ∏è AJUSTAR si es necesario\n",
    "dataset_path = Path(DATASET_DIR)\n",
    "\n",
    "print(\"üîç Verificando dataset...\\n\")\n",
    "\n",
    "# Verificar archivos requeridos\n",
    "required_files = ['config.json', 'dataset.jsonl']\n",
    "for file in required_files:\n",
    "    file_path = dataset_path / file\n",
    "    if file_path.exists():\n",
    "        print(f\"‚úÖ {file}\")\n",
    "        if file == 'config.json':\n",
    "            with open(file_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "                print(f\"   - Audio: {config.get('audio', {}).get('sample_rate')} Hz\")\n",
    "                print(f\"   - Idioma: {config.get('espeak', {}).get('voice')}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} no encontrado\")\n",
    "\n",
    "# Contar muestras\n",
    "jsonl_path = dataset_path / 'dataset.jsonl'\n",
    "if jsonl_path.exists():\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        num_samples = sum(1 for _ in f)\n",
    "    print(f\"\\nüìä Total de muestras: {num_samples}\")\n",
    "    \n",
    "    # Calcular duraci√≥n aproximada de entrenamiento\n",
    "    samples_per_epoch = num_samples\n",
    "    time_per_sample = 0.3  # segundos aproximados por muestra en GPU T4\n",
    "    time_per_epoch = (samples_per_epoch * time_per_sample) / 60\n",
    "    print(f\"‚è±Ô∏è Tiempo estimado por √©poca: ~{time_per_epoch:.1f} minutos (GPU T4)\")\n",
    "else:\n",
    "    print(\"‚ùå No se pudo contar muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Entrenar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de entrenamiento\n",
    "DATASET_DIR = \"datasets/sig\"  # ‚¨ÖÔ∏è AJUSTAR\n",
    "MAX_EPOCHS = 100\n",
    "BATCH_SIZE = 16  # Ajustar seg√∫n VRAM disponible\n",
    "CHECKPOINT_EPOCHS = 5\n",
    "VALIDATION_SPLIT = 0.05\n",
    "NUM_TEST_EXAMPLES = 0\n",
    "PRECISION = \"32\"  # Usar \"32\" para mejor compatibilidad\n",
    "\n",
    "# Entrenar modelo con piper_train\n",
    "!python -m piper_train \\\n",
    "  --dataset-dir {DATASET_DIR} \\\n",
    "  --accelerator gpu \\\n",
    "  --devices 1 \\\n",
    "  --batch-size {BATCH_SIZE} \\\n",
    "  --validation-split {VALIDATION_SPLIT} \\\n",
    "  --num-test-examples {NUM_TEST_EXAMPLES} \\\n",
    "  --max_epochs {MAX_EPOCHS} \\\n",
    "  --resume_from_checkpoint models_base/en_US-lessac-high.ckpt \\\n",
    "  --checkpoint-epochs {CHECKPOINT_EPOCHS} \\\n",
    "  --precision {PRECISION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Configuraci√≥n Avanzada\n",
    "\n",
    "Ajusta estos par√°metros seg√∫n tu caso:\n",
    "\n",
    "- **BATCH_SIZE**: \n",
    "  - 16-32 para T4 (16GB)\n",
    "  - 8-16 para GPUs con menos VRAM\n",
    "  - Reduce si obtienes errores de memoria\n",
    "  \n",
    "- **MAX_EPOCHS**: \n",
    "  - M√≠nimo 100 para resultados aceptables\n",
    "  - 500-1000+ para mejor calidad\n",
    "  \n",
    "- **CHECKPOINT_EPOCHS**: Cada cu√°ntas √©pocas guardar un checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Monitorear Progreso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitorear el progreso durante el entrenamiento\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def monitor_training(dataset_dir, update_interval=30):\n",
    "    \"\"\"\n",
    "    Monitorea el entrenamiento en tiempo real\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: Directorio del dataset\n",
    "        update_interval: Segundos entre actualizaciones\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    \n",
    "    logs_dir = Path(dataset_dir) / \"lightning_logs\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Buscar √∫ltima versi√≥n\n",
    "            versions = sorted(logs_dir.glob(\"version_*\"))\n",
    "            if not versions:\n",
    "                print(\"‚è≥ Esperando inicio del entrenamiento...\")\n",
    "                time.sleep(update_interval)\n",
    "                continue\n",
    "            \n",
    "            metrics_file = versions[-1] / \"metrics.csv\"\n",
    "            if metrics_file.exists():\n",
    "                df = pd.read_csv(metrics_file)\n",
    "                \n",
    "                print(\"=\" * 60)\n",
    "                print(\"üìä PROGRESO DEL ENTRENAMIENTO\")\n",
    "                print(\"=\" * 60)\n",
    "                print(f\"\\n√âpoca actual: {int(df['epoch'].max())}\")\n",
    "                print(f\"Total de pasos: {int(df['step'].max())}\")\n",
    "                print(f\"\\n--- √öltimas 5 m√©tricas ---\")\n",
    "                print(df[['epoch', 'loss_gen_all', 'loss_disc_all']].tail())\n",
    "                print(\"\\nüí° Presiona el bot√≥n STOP para detener el monitoreo\")\n",
    "                \n",
    "            time.sleep(update_interval)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚úÖ Monitoreo detenido\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "            time.sleep(update_interval)\n",
    "\n",
    "# Para iniciar el monitoreo (ejecutar en otra celda mientras entrena):\n",
    "# monitor_training(DATASET_DIR, update_interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver m√©tricas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
    "versions = sorted(logs_dir.glob(\"version_*\"))\n",
    "if versions:\n",
    "    metrics = versions[-1] / \"metrics.csv\"\n",
    "    if metrics.exists():\n",
    "        df = pd.read_csv(metrics)\n",
    "        print(df.tail())\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(df['epoch'], df['loss_gen_all'])\n",
    "        plt.title('Generator Loss')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(df['epoch'], df['loss_disc_all'])\n",
    "        plt.title('Discriminator Loss')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Exportar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a ONNX\n",
    "from pathlib import Path\n",
    "\n",
    "# Buscar el √∫ltimo checkpoint\n",
    "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
    "versions = sorted(logs_dir.glob(\"version_*\"))\n",
    "\n",
    "if not versions:\n",
    "    print(\"‚ùå No se encontraron versiones de entrenamiento\")\n",
    "else:\n",
    "    latest_version = versions[-1]\n",
    "    checkpoints = sorted(latest_version.glob(\"checkpoints/*.ckpt\"))\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"‚ùå No se encontraron checkpoints\")\n",
    "    else:\n",
    "        CHECKPOINT = str(checkpoints[-1])\n",
    "        print(f\"üì¶ Exportando checkpoint: {CHECKPOINT}\")\n",
    "        \n",
    "        # Crear directorio de salida\n",
    "        !mkdir -p outputs\n",
    "        \n",
    "        # Exportar a ONNX usando el m√≥dulo correcto\n",
    "        !python3 -m piper_train.export_onnx \\\n",
    "            \"{CHECKPOINT}\" \\\n",
    "            \"/content/piper-training/outputs/model.onnx\"\n",
    "        \n",
    "        # Copiar archivo de configuraci√≥n JSON\n",
    "        config_src = Path(DATASET_DIR) / \"config.json\"\n",
    "        if config_src.exists():\n",
    "            !cp \"{config_src}\" outputs/model.onnx.json\n",
    "            print(\"‚úÖ Modelo exportado a outputs/\")\n",
    "            print(f\"   - model.onnx\")\n",
    "            print(f\"   - model.onnx.json\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se encontr√≥ config.json en el dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Descargar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en Google Drive\n",
    "!mkdir -p \"/content/drive/MyDrive/piper-models/trained_model\"\n",
    "!cp -r outputs/* \"/content/drive/MyDrive/piper-models/trained_model/\"\n",
    "print(\"‚úÖ Guardado en Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O descargar directamente\n",
    "from google.colab import files\n",
    "!zip -r model_trained.zip outputs/\n",
    "files.download(\"model_trained.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Probar el Modelo\n",
    "\n",
    "Prueba tu modelo entrenado directamente en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar piper-tts para pruebas\n",
    "!pip install -q piper-tts\n",
    "\n",
    "# Generar audio de prueba\n",
    "TEST_TEXT = \"Hola, esta es una prueba de mi voz personalizada con Piper TTS.\"\n",
    "OUTPUT_WAV = \"prueba.wav\"\n",
    "\n",
    "!echo \"{TEST_TEXT}\" | piper --model outputs/model.onnx --output_file {OUTPUT_WAV}\n",
    "\n",
    "# Reproducir audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "if os.path.exists(OUTPUT_WAV):\n",
    "    print(\"‚úÖ Audio generado exitosamente\")\n",
    "    display(Audio(OUTPUT_WAV, autoplay=False))\n",
    "else:\n",
    "    print(\"‚ùå No se pudo generar el audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Soluci√≥n de Problemas\n",
    "\n",
    "### Errores comunes y soluciones:\n",
    "\n",
    "**1. Error de memoria GPU (CUDA out of memory)**\n",
    "- Reduce `BATCH_SIZE` (prueba con 8, 4, o incluso 2)\n",
    "- Cierra otras celdas que usen GPU\n",
    "- Reinicia el runtime: `Runtime > Restart runtime`\n",
    "\n",
    "**2. Error \"No module named 'piper_train'\"**\n",
    "- Verifica que ejecutaste la celda de instalaci√≥n de dependencias\n",
    "- Aseg√∫rate de estar en el directorio correcto\n",
    "\n",
    "**3. Dataset vac√≠o o sin muestras**\n",
    "- Verifica que `dataset.jsonl` tenga contenido\n",
    "- Revisa que los archivos de audio est√©n en el formato correcto\n",
    "- Ejecuta la celda de verificaci√≥n de dataset\n",
    "\n",
    "**4. P√©rdidas (losses) no disminuyen**\n",
    "- Es normal al principio del entrenamiento\n",
    "- Espera al menos 50-100 √©pocas antes de evaluar\n",
    "- Verifica que el modelo base sea compatible con tu idioma\n",
    "\n",
    "**5. Entrenamiento muy lento**\n",
    "- Verifica que est√©s usando GPU: `Runtime > Change runtime type > GPU`\n",
    "- Comprueba disponibilidad con `!nvidia-smi`\n",
    "- GPU T4 es recomendada para mejor rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Limpieza (Opcional)\n",
    "\n",
    "Libera espacio eliminando archivos temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar archivos temporales para liberar espacio\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üßπ Limpiando archivos temporales...\\n\")\n",
    "\n",
    "# Eliminar logs antiguos (mantener solo el √∫ltimo)\n",
    "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"\n",
    "if logs_dir.exists():\n",
    "    versions = sorted(logs_dir.glob(\"version_*\"))\n",
    "    if len(versions) > 1:\n",
    "        for old_version in versions[:-1]:\n",
    "            shutil.rmtree(old_version)\n",
    "            print(f\"‚úÖ Eliminado: {old_version.name}\")\n",
    "\n",
    "# Eliminar checkpoints intermedios (mantener solo cada 10 √©pocas)\n",
    "if versions:\n",
    "    checkpoints_dir = versions[-1] / \"checkpoints\"\n",
    "    if checkpoints_dir.exists():\n",
    "        checkpoints = sorted(checkpoints_dir.glob(\"*.ckpt\"))\n",
    "        for ckpt in checkpoints[:-1]:  # Mantener el √∫ltimo\n",
    "            epoch = ckpt.stem.split('-')[0].replace('epoch=', '')\n",
    "            if epoch.isdigit() and int(epoch) % 10 != 0:\n",
    "                ckpt.unlink()\n",
    "                print(f\"‚úÖ Eliminado checkpoint: {ckpt.name}\")\n",
    "\n",
    "# Verificar espacio disponible\n",
    "total, used, free = shutil.disk_usage(\"/\")\n",
    "print(f\"\\nüíæ Espacio disponible: {free // (2**30)} GB\")\n",
    "print(\"‚úÖ Limpieza completada\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
