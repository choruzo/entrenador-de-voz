{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ™ï¸ Entrenamiento de Voz Piper TTS en Google Colab",
        "",
        "Este notebook permite entrenar modelos de voz Piper TTS con GPU gratuita de Google Colab.",
        "",
        "**GPU recomendada:** T4 o superior  ",
        "**Tiempo por Ã©poca:** ~10-30 minutos con GPU (vs 30-60 min en CPU)",
        "",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ ConfiguraciÃ³n Inicial",
        "",
        "Verificar GPU y montar Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar GPU disponible",
        "!nvidia-smi",
        "",
        "import torch",
        "print(f\"\\nâœ… PyTorch version: {torch.__version__}\")",
        "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")",
        "if torch.cuda.is_available():",
        "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")",
        "    print(f\"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montar Google Drive",
        "from google.colab import drive",
        "drive.mount('/content/drive')",
        "",
        "# Crear directorio de trabajo",
        "!mkdir -p /content/piper-training",
        "%cd /content/piper-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ InstalaciÃ³n de Dependencias",
        "",
        "Instalar Piper y todas las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "set -e",
        "echo \"ðŸ“¦ Instalando dependencias del sistema...\"",
        "apt-get update -qq",
        "apt-get install -y -qq espeak-ng wget git > /dev/null 2>&1",
        "echo \"âœ… espeak-ng instalado\"",
        "espeak-ng --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "set -e",
        "echo \"ðŸ“¦ Instalando piper-phonemize...\"",
        "if [ ! -d \"piper_phonemize\" ]; then",
        "    wget -q https://github.com/rhasspy/piper-phonemize/releases/download/v1.2.0/piper_phonemize-amd64.tar.gz",
        "    tar -xzf piper_phonemize-amd64.tar.gz",
        "    rm piper_phonemize-amd64.tar.gz",
        "    echo \"âœ… piper-phonemize instalado\"",
        "else",
        "    echo \"âœ… piper-phonemize ya existe\"",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "set -e",
        "echo \"ðŸ“¦ Clonando Piper...\"",
        "if [ ! -d \"piper\" ]; then",
        "    git clone -q https://github.com/rhasspy/piper.git",
        "    echo \"âœ… Piper clonado\"",
        "else",
        "    echo \"âœ… Piper ya existe\"",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar dependencias Python",
        "print(\"ðŸ“¦ Instalando PyTorch y dependencias...\")",
        "!pip install -q torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121",
        "!pip install -q \"numpy>=1.26,<2.0\"",
        "!pip install -q \"pytorch-lightning>=1.9.0,<2.0.0\"",
        "!pip install -q librosa onnxruntime scipy cython",
        "",
        "%cd piper/src/python",
        "!pip install -q -e . --no-deps",
        "%cd /content/piper-training",
        "",
        "print(\"âœ… Dependencias instaladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ Descargar Modelo Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "set -e",
        "mkdir -p models_base && cd models_base",
        "if [ ! -f \"en_US-lessac-high.ckpt\" ]; then",
        "    echo \"ðŸ“¥ Descargando checkpoint (952 MB)...\"",
        "    wget -q --show-progress \\",
        "        \"https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/7bf647cb000d8c8319c6cdd4289dd6b7d0d3eeb8/en/en_US/lessac/high/epoch=2218-step=838782.ckpt\" \\",
        "        -O en_US-lessac-high.ckpt",
        "    echo \"âœ… Checkpoint descargado\"",
        "else",
        "    echo \"âœ… Checkpoint ya existe\"",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ Configurar Dataset",
        "",
        "Sube tu dataset preprocesado o procesa uno nuevo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCIÃ“N A: Copiar desde Google Drive",
        "DRIVE_PATH = \"/content/drive/MyDrive/piper-datasets/sig\"  # â¬…ï¸ AJUSTAR",
        "",
        "!mkdir -p datasets",
        "!cp -r \"{DRIVE_PATH}\" datasets/",
        "import os",
        "DATASET_NAME = os.path.basename(DRIVE_PATH)",
        "DATASET_DIR = f\"datasets/{DATASET_NAME}\"",
        "print(f\"âœ… Dataset copiado: {DATASET_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCIÃ“N B: Subir ZIP y preprocesar",
        "from google.colab import files",
        "uploaded = files.upload()  # Sube tu dataset.zip aquÃ­"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5ï¸âƒ£ Entrenar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ConfiguraciÃ³n de entrenamiento",
        "DATASET_DIR = \"datasets/sig\"  # â¬…ï¸ AJUSTAR",
        "MAX_EPOCHS = 100",
        "BATCH_SIZE = 16  # Ajustar segÃºn VRAM",
        "CHECKPOINT_EPOCHS = 5",
        "",
        "!python -m piper_train \\",
        "  --dataset-dir {DATASET_DIR} \\",
        "  --accelerator gpu \\",
        "  --devices 1 \\",
        "  --batch-size {BATCH_SIZE} \\",
        "  --validation-split 0.05 \\",
        "  --num-test-examples 0 \\",
        "  --max_epochs {MAX_EPOCHS} \\",
        "  --quality high \\",
        "  --resume_from_checkpoint models_base/en_US-lessac-high.ckpt \\",
        "  --checkpoint-epochs {CHECKPOINT_EPOCHS} \\",
        "  --precision 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6ï¸âƒ£ Monitorear Progreso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ver mÃ©tricas",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "from pathlib import Path",
        "",
        "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"",
        "versions = sorted(logs_dir.glob(\"version_*\"))",
        "if versions:",
        "    metrics = versions[-1] / \"metrics.csv\"",
        "    if metrics.exists():",
        "        df = pd.read_csv(metrics)",
        "        print(df.tail())",
        "        ",
        "        plt.figure(figsize=(12, 4))",
        "        plt.subplot(1, 2, 1)",
        "        plt.plot(df['epoch'], df['loss_gen_all'])",
        "        plt.title('Generator Loss')",
        "        plt.subplot(1, 2, 2)",
        "        plt.plot(df['epoch'], df['loss_disc_all'])",
        "        plt.title('Discriminator Loss')",
        "        plt.tight_layout()",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7ï¸âƒ£ Exportar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar a ONNX",
        "from pathlib import Path",
        "logs_dir = Path(DATASET_DIR) / \"lightning_logs\"",
        "versions = sorted(logs_dir.glob(\"version_*\"))",
        "checkpoints = sorted(versions[-1].glob(\"checkpoints/*.ckpt\"))",
        "CHECKPOINT = str(checkpoints[-1])",
        "",
        "!mkdir -p outputs",
        "!cd piper/src/python && python3 -m piper_train.export_onnx \\",
        "    \"{CHECKPOINT}\" \\",
        "    \"/content/piper-training/outputs/model.onnx\"",
        "",
        "!cp {DATASET_DIR}/config.json outputs/model.onnx.json",
        "print(\"âœ… Modelo exportado a outputs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8ï¸âƒ£ Descargar Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar en Google Drive",
        "!mkdir -p \"/content/drive/MyDrive/piper-models/trained_model\"",
        "!cp -r outputs/* \"/content/drive/MyDrive/piper-models/trained_model/\"",
        "print(\"âœ… Guardado en Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# O descargar directamente",
        "from google.colab import files",
        "!zip -r model_trained.zip outputs/",
        "files.download(\"model_trained.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}